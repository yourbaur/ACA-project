{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "developmental-vertical",
   "metadata": {},
   "source": [
    "Title: K-means clustering\n",
    "\n",
    "Authors: Bauyrzhan Taimanov - Madina Amanatayeva\n",
    "\n",
    "Date: Jan 18, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fresh-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-defeat",
   "metadata": {},
   "source": [
    "# 0) Context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-contents",
   "metadata": {},
   "source": [
    "## Customer Segmentation with Parallel K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-public",
   "metadata": {},
   "source": [
    "In business, we often say \"Customer is king\" and \"Customer is always right.\" Basically, it means we need to focus on what customers want. So, the idea here is to use this concept to group products that match what different groups of customers like. This can help a lot in online stores because it means showing customers the products they're most likely to be interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-offering",
   "metadata": {},
   "source": [
    "![alt text](https://editor.analyticsvidhya.com/uploads/73654cluster.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-operation",
   "metadata": {},
   "source": [
    "This concept can be handy in places where we use digital marketing tools to promote products. For example, in some types of ads, we show products to people based on things like their interests. Then, by looking at whether they click on the ads or not, we can figure out who else might like those products.\n",
    "Similarly, in other types of ads, we bid for space to show our products to people in real-time. We do this based on what we know about the people seeing the ads and what's worked well in the past. This way, we can make sure we're showing the right products to the right people at the right time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-thumbnail",
   "metadata": {},
   "source": [
    "## Concept\n",
    "\n",
    "Customers buy products based on different needs and constraints, like budget and preference for certain items. To understand these behaviors, we can analyze customer invoice data and other non-personal data.\n",
    "Here's a simplified approach:\n",
    "* Analyze customer invoice data to find buying patterns.\n",
    "* Use clustering algorithms to group customers based on similar purchase behaviors.\n",
    "* Identify products that match each customer group's preferences.\n",
    "* Tailor digital campaigns to each customer group for better targeting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-quest",
   "metadata": {},
   "source": [
    "Though, with our current data limitations, we may not have all the necessary details to build a complete model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-quality",
   "metadata": {},
   "source": [
    "# 1) Analysis of the Serial Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-anthony",
   "metadata": {},
   "source": [
    "## K-Means Algorithm \n",
    "\n",
    "K-means clustering stands as a well-known machine learning technique utilized for customer segmentation, driven by identifying similarities among them. Its goal is to discern k clusters within the data, with each cluster denoting a cohort of customers sharing common traits. The algorithm hinges on centroids, acting as the central points of these clusters, and employs distance measures to allocate customers into the relevant clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-canadian",
   "metadata": {},
   "source": [
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/K-means_convergence.gif/440px-K-means_convergence.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-dubai",
   "metadata": {},
   "source": [
    "## How does algorithm work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-copying",
   "metadata": {},
   "source": [
    "The K-means algorithm is an iterative clustering method that divides a dataset into K clusters, assigning each data point to the cluster with the closest mean, or centroid. Below outlines the functioning of the algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-tattoo",
   "metadata": {},
   "source": [
    "### 1) Initialization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-ireland",
   "metadata": {},
   "source": [
    " Randomly initialize K cluster centroids. These centroids represent the initial guesses for the cluster centers.\n",
    "\n",
    "Formula: \n",
    "Random initizalization of centroids\n",
    "{Î¼1,Î¼2,Î¼3,â€¦â€¦..,Î¼n}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-armstrong",
   "metadata": {},
   "source": [
    "### 2)  Data Points to Nearest Centroid:\n",
    "For each data point in the dataset, calculate the distance to each centroid using a distance metric (usually Euclidean distance). Assign each data point to the cluster with the nearest centroid.\n",
    "\n",
    "Formula: \n",
    "1) Find euclean distance between data point xi and centroid Î¼k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-perry",
   "metadata": {},
   "source": [
    "![alt text](formulas/formula0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-interest",
   "metadata": {},
   "source": [
    "2) Assign data point xi to the cluster with the nearest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-pursuit",
   "metadata": {},
   "source": [
    "![alt text](formulas/formula1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-mainland",
   "metadata": {},
   "source": [
    "### 3) Updating centroids\n",
    "Calculate the mean of all data points assigned to each cluster and update the centroid to this mean.\n",
    "\n",
    "Formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-class",
   "metadata": {},
   "source": [
    "Mean of data points assigned to cluster k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-people",
   "metadata": {},
   "source": [
    "![alt text](formulas/formula2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-packing",
   "metadata": {},
   "source": [
    "### 4) Repeat Until Convergence\n",
    "\n",
    "   - Convergence criteria: The algorithm iteratively performs steps 2 and 3 until convergence is achieved. Convergence occurs when either of the following conditions is met:\n",
    "   - The centroids no longer change significantly between iterations. This can be determined by comparing the current centroids to the centroids from the previous iteration and checking if the change is below a predefined threshold.\n",
    "   - A maximum number of iterations is reached.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-outdoors",
   "metadata": {},
   "source": [
    "### 5) Final Clustering\n",
    "\n",
    "   - Once convergence is achieved, the final clustering is obtained, with each data point assigned to a specific cluster based on the nearest centroid.\n",
    "   - The final clusters represent groups of data points that are similar to each other in terms of their features, with the centroids serving as representative points of each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-cycling",
   "metadata": {},
   "source": [
    "The goal of the K-means algorithm is to minimize the within-cluster sum of squares (WCSS), which is the sum of the squared distances between each data point and its assigned centroid within the cluster. This objective function represents the compactness of the clusters, aiming to minimize the variance within each cluster while maximizing the separation between clusters.\n",
    "\n",
    "It's important to note that K-means is sensitive to the initial placement of centroids, and different initializations may lead to different clustering results. Therefore, it's common to run the algorithm multiple times with different initializations and choose the clustering with the lowest WCSS as the final result. Additionally, determining the optimal number of clusters (K) is a critical step and is often done using techniques like the Elbow Method or silhouette analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-prescription",
   "metadata": {},
   "source": [
    "Our implementation of the K-Means Clustering algorithm is as follows:\n",
    "\n",
    "It is based on the C++ code found at the following GitHub repository: https://github.com/aditya1601/kmeans-clustering-cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-narrow",
   "metadata": {},
   "source": [
    "```cpp\n",
    "  void run(vector<Point> &all_points)\n",
    "    {\n",
    "        total_points = all_points.size();\n",
    "        dimensions = all_points[0].getDimensions();\n",
    "\n",
    "        // Initializing Clusters\n",
    "        vector<int> used_pointIds;\n",
    "\n",
    "        for (int i = 1; i <= K; i++)\n",
    "        {\n",
    "            while (true)\n",
    "            {\n",
    "                int index = rand() % total_points;\n",
    "\n",
    "                if (find(used_pointIds.begin(), used_pointIds.end(), index) ==\n",
    "                    used_pointIds.end())\n",
    "                {\n",
    "                    used_pointIds.push_back(index);\n",
    "                    all_points[index].setCluster(i);\n",
    "                    Cluster cluster(i, all_points[index]);\n",
    "                    clusters.push_back(cluster);\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "       cout << \"Clusters initialized = \" << clusters.size() << endl\n",
    "             << endl;\n",
    "\n",
    "        cout << \"Running K-Means Clustering..\" << endl;\n",
    "\n",
    "        int iter = 1;\n",
    "        while (true)\n",
    "        {\n",
    "            cout << \"Iter - \" << iter << \"/\" << iters << endl;\n",
    "            bool done = true;\n",
    "\n",
    "            // Add all points to their nearest cluster\n",
    "            #pragma omp parallel for reduction(&&: done) num_threads(16)\n",
    "            for (int i = 0; i < total_points; i++)\n",
    "            {\n",
    "                int currentClusterId = all_points[i].getCluster();\n",
    "                int nearestClusterId = getNearestClusterId(all_points[i]);\n",
    "\n",
    "                if (currentClusterId != nearestClusterId)\n",
    "                {\n",
    "                    all_points[i].setCluster(nearestClusterId);\n",
    "                    done = false;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // clear all existing clusters\n",
    "            clearClusters();\n",
    "             // reassign points to their new clusters\n",
    "            for (int i = 0; i < total_points; i++)\n",
    "            {\n",
    "                // cluster index is ID-1\n",
    "                clusters[all_points[i].getCluster() - 1].addPoint(all_points[i]);\n",
    "            }\n",
    "\n",
    "            // Recalculating the center of each cluster\n",
    "            for (int i = 0; i < K; i++)\n",
    "            {\n",
    "                int ClusterSize = clusters[i].getSize();\n",
    "\n",
    "                for (int j = 0; j < dimensions; j++)\n",
    "                {\n",
    "                    double sum = 0.0;\n",
    "                    if (ClusterSize > 0)\n",
    "                    {\n",
    "                        #pragma omp parallel for reduction(+: sum) num_threads(16)\n",
    "                        for (int p = 0; p < ClusterSize; p++)\n",
    "                        {\n",
    "                            sum += clusters[i].getPoint(p).getVal(j);\n",
    "                        }\n",
    "                        clusters[i].setCentroidByPos(j, sum / ClusterSize);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "              if (done || iter >= iters)\n",
    "            {\n",
    "                cout << \"Clustering completed in iteration : \" << iter << endl\n",
    "                     << endl;\n",
    "                break;\n",
    "            }\n",
    "            iter++;\n",
    "        }\n",
    "\n",
    "        ofstream pointsFile;\n",
    "        pointsFile.open(output_dir + \"/\" + to_string(K) + \"-points.txt\", ios::out);\n",
    "\n",
    "        for (int i = 0; i < total_points; i++)\n",
    "        {\n",
    "            pointsFile << all_points[i].getCluster() << endl;\n",
    "        }\n",
    "\n",
    "        pointsFile.close();\n",
    "\n",
    "        // Write cluster centers to file\n",
    "        ofstream outfile;\n",
    "        outfile.open(output_dir + \"/\" + to_string(K) + \"-clusters.txt\");\n",
    "        if (outfile.is_open())\n",
    "        {\n",
    "             for (int i = 0; i < K; i++)\n",
    "            {\n",
    "                cout << \"Cluster \" << clusters[i].getId() << \" centroid : \";\n",
    "                for (int j = 0; j < dimensions; j++)\n",
    "                {\n",
    "                    cout << clusters[i].getCentroidByPos(j) << \" \";    // Output to console\n",
    "                    outfile << clusters[i].getCentroidByPos(j) << \" \"; // Output to file\n",
    "                }\n",
    "                cout << endl;\n",
    "                outfile << endl;\n",
    "            }\n",
    "            outfile.close();\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            cout << \"Error: Unable to write to clusters.txt\";\n",
    "        }\n",
    "    }\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-marina",
   "metadata": {},
   "source": [
    "# 2) A-priori study of available parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-independence",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-sentence",
   "metadata": {},
   "source": [
    "For the shop owners, whether they operate an e-commerce platform or a physical supermarket, understanding their customers is crucial, regardless of the scale of their business, be it a small local shop or a large corporation like Amazon or Netflix.\n",
    "They are able to gather basic customer data from those who hold membership cards, including details such as age, annual income, and spending score. The spending score reflects customer behavior and purchasing patterns. With new products entering the market, they aim to tailor your marketing efforts to specific customer segments for each product.\n",
    "Clustering, a fundamental problem in unsupervised learning, becomes essential in categorizing individuals into groups based on similarities. These groups, known as clusters, consist of data points that share more similarities within the cluster than with data points in other clusters. Distance-based clustering involves grouping data points into clusters where the distances between points within a cluster are minimized, while distances between clusters are maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48bb3df",
   "metadata": {},
   "source": [
    "K-means clustering algorithm to cluster customer data based on age, income, spending score, and frequency. Here's an overview of the functionalities:\n",
    "\n",
    "* Point Structure: Represents a customer with attributes such as age, income, spending score, frequency, and cluster assignment.\n",
    "* euclideanDistance Function: Calculates the Euclidean distance between two customer points based on their attributes.\n",
    "* updateCentroids Function: Updates the centroids of clusters based on the mean of the points assigned to each cluster.\n",
    "* kmeans Function: Implements the K-means clustering algorithm by iteratively assigning points to the nearest centroids and updating centroids until convergence.\n",
    "* main Function: Reads customer data from a file, initializes centroids randomly, performs K-means clustering, and measures execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1883fac4",
   "metadata": {},
   "source": [
    "## Data Structures:\n",
    "\n",
    "* Points: Vector of customer data points.\n",
    "* Centroids: Vector of centroid points representing cluster centers.\n",
    "* Cluster Assignments: Each point has a cluster assignment, which needs to be updated during the K-means iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a011d18",
   "metadata": {},
   "source": [
    "## Potential Parallelization parts:\n",
    "\n",
    "Point Assignment to Centroids (K-means Iteration):\n",
    "* Parallelizable: The loop that assigns each point to the nearest centroid can be parallelized because each point's assignment is independent of others.\n",
    "* Strategy: Employ parallelism using parallel constructs like OpenMP or threading libraries to distribute the workload across multiple threads.\n",
    "\n",
    "Centroid Update:\n",
    "* Parallelizable: The computation of new centroid positions involves aggregating attributes of points assigned to each centroid.\n",
    "* Strategy: Distribute the centroid update calculations across multiple threads or processes, possibly using parallel constructs like OpenMP or MPI.\n",
    "\n",
    "Convergence Check:\n",
    "* Not Parallelizable: The convergence check compares the distances between old and new centroids, which requires synchronous access to all centroids.\n",
    "* Strategy: This part cannot be parallelized efficiently as it involves a collective operation across all centroids.\n",
    "\n",
    "Initialization of Centroids:\n",
    "* Partially Parallelizable: The random initialization of centroids can be parallelized to generate initial centroids more efficiently.\n",
    "* Strategy: Employ parallel random number generation techniques to initialize centroids in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aff3ee0",
   "metadata": {},
   "source": [
    "## Communication & Synchronization:\n",
    "\n",
    "* Synchronization: Synchronization can be used when updating shared data structures like centroids and cluster assignments to avoid race conditions.\n",
    "* Communication: Minimal communication is required during the parallelization process, primarily for sharing the updated centroid positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e79178",
   "metadata": {},
   "source": [
    "## Expected Results:\n",
    "\n",
    "* Speed-up: The parallelization of point assignment and centroid update phases is expected to provide significant speed-up, especially for large datasets and a high number of clusters.\n",
    "* Amdahl's Law: Amdahl's Law can be applied to estimate the potential speed-up, considering the parallelizable and non-parallelizable portions of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8f8b8",
   "metadata": {},
   "source": [
    "## Amdahl's Law \n",
    "Amdahl's Law is a theoretical model used to estimate the potential speed-up of a parallelized program. It states that the overall speed-up of a program is limited by the proportion of the program that cannot be parallelized. Let's analyze Amdahl's Law for the our project:\n",
    "1. Identifying Parallelizable Portions:\n",
    "* Based on the previous analysis, the main portions that can be parallelized are the loop for point assignment to centroids and the loop for centroid updates.\n",
    "* The initialization of centroids and convergence check cannot be parallelized efficiently due to their nature.\n",
    "\n",
    "2. Calculating the Fraction of the Code That Can Be Parallelized: â¨\n",
    "* Let's denote the fraction of the code that can be parallelized as â¨\n",
    "* In this case, â¨ represents the proportion of the code related to point assignment and centroid updates that can be parallelized.\n",
    "* Since we're parallelizing two main loops, we can assume that approximately 80% of the code is parallelizable, and â¨ = 0.8\n",
    "\n",
    "3. Calculating the Theoretical Speed-up:\n",
    "* According to Amdahl's Law, the theoretical speed-up ð‘º of a program with ð‘ processors is given by the formula:\n",
    "![alt text](formulas/formula4.png)\n",
    "\n",
    "Let's assume we have 4 processors (ð‘=4).\n",
    "\n",
    "![alt text](formulas/formula5.png)\n",
    "\n",
    "4. Interpretation:\n",
    "The theoretical speed-up ð‘º calculated using Amdahl's Law is 2.5 times faster than the serial execution. This means that if we parallelize 80% of the code across 4 processors, we can expect the program to run approximately 2.5 times faster compared to the serial execution.\n",
    "\n",
    "5. Limitations and Considerations:\n",
    "Amdahl's Law provides an idealized theoretical estimate and may not perfectly reflect the real-world performance due to factors like overheads, communication costs, and varying execution times of different portions of the code.\n",
    "It assumes perfect scalability and uniform workload distribution, which may not always be achievable in practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
